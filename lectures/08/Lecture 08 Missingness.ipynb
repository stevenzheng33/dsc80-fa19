{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# set defaults\n",
    "plt.style.use('seaborn-white')   # seaborn custom plot style\n",
    "plt.rc('figure', dpi=100, figsize=(7, 5))   # set default size/resolution\n",
    "plt.rc('font', size=12)   # font size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 8\n",
    "\n",
    "### Missingness Mechansisms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Imperfect Data\n",
    "\n",
    "<img src=\"imgs/image_0.png\">\n",
    "\n",
    "* The \"true\" (probability) model is an idealized approximation of the Data Generating Process.\n",
    "* The data generating process is the phenomenon we want to understand.\n",
    "* The recorded data is *supposed* to \"well represent\" the data generating process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Imperfect Data\n",
    "\n",
    "<img src=\"imgs/image_1.png\">\n",
    "\n",
    "* Problem 1: your data is not representative? (poor sample of events).\n",
    "* Problem 2: your recording process is incomplete.\n",
    "\n",
    "These are only problems when there is *systematic bias* in the result!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Imperfect Data\n",
    "\n",
    "* Non-representative samples are identified with domain research!\n",
    "    - Does the description of the data look like your understanding of the data generating process?\n",
    "* Incomplete measurements are missing data!\n",
    "    - Understanding how *portions* of your data are missing affects the quality of your sample.\n",
    "    - There are techniques to understand when missing measurements are representative of the rest of the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Understanding How Data is Absent\n",
    "\n",
    "* Missing by Design (MD)\n",
    "    \n",
    "* Ignorable Missing Data:\n",
    "    - Unconditionally ignorable (Missing Completely at Random: MCAR)\n",
    "    - Conditionally ignorable (Missing at Random: MAR)\n",
    "    \n",
    "* Non-Ignorable Missing Data (Not Missing at Random: NMAR)\n",
    "\n",
    "[(see wikipedia synopsis)](https://en.wikipedia.org/wiki/Missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Missing by Design (MD)\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "    \n",
    "\n",
    "* The field being absent is deterministic. \n",
    "* A function of the rows of the dataset that can:\n",
    "    - exactly predict when a colum will be null,\n",
    "    - with only knowledge of the other columns.\n",
    "\n",
    "\n",
    "<img src=\"imgs/skiplogic.png\"/>\n",
    "\n",
    "</div>\n",
    "    \n",
    "[(reference)](https://stats.stackexchange.com/questions/201782/meaning-of-missing-by-design-in-longitudinal-studies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Unconditionally ignorable (MCAR)\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "\n",
    "* The missing value isn't associated to the (actual, unreported) value itself, nor the values in any other fields.\n",
    "* The missingness is unconditionally uniform across rows.\n",
    "* Example 1: follow-up survey questions on a random sample of respondents.\n",
    "* Example 2: Water damage to paper forms prior to entry (assuming shuffled forms).\n",
    "\n",
    "<img src=\"imgs/water.jpg\" width=\"50%\"/>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conditionally Ignorable (MAR)\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "\n",
    "* A missing value may depend only on values of other fields, but not its own.\n",
    "* The missingness is uniform across rows, perhaps conditional on another column.\n",
    "* Example 1: For really sick patients, clinicians may not draw blood for routine labs.\n",
    "* Example 2: People working in a Service Industry are less likely to report their income.\n",
    "\n",
    "<img src=\"imgs/tip.jpg\" width=\"50%\"/>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Non-Ignorable (NMAR)\n",
    "\n",
    "* A missing value depends on the value of the (actual, unreported) variable that's missing.\n",
    "* Example 1: people with high income are less likely to report income.\n",
    "* Example 2: a person doesn't take a drug test because they took drugs the day before.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discussion Questions\n",
    "\n",
    "For each of the following datasets, decide whether they are MD, MCAR, MAR, NMAR:\n",
    "\n",
    "* Self-reported income in the *follow-up* questionnaire of the census.\n",
    "* A table (for a medical study) with column `gender` and column `age`. Age has missing values.\n",
    "* Measurements from the Hubble Space Telescope (dropped data during transmission).\n",
    "* The serial number of returned Macbook Pros, in a table of order information. \n",
    "* SAT scores reported by an institution for College Ranking scores.\n",
    "* A table with a single column: self-reported education (with missing values).\n",
    "* Midterm report with three columns (`ver.1`, `ver.2`, `ver.3`). â…” of the entries in the report are `NaN`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Diagnosis of missingness:\n",
    "\n",
    "* Depends on the dataset and its attributes.\n",
    "* Depends on the population / data generating processing under consideration.\n",
    "* Requires understanding the severity and effect of each possible type of missingness.\n",
    "\n",
    "Data with missing data is likely not a representative sample of the true population! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Missing Summary\n",
    "\n",
    "* **MCAR**: Data is *Unconditionally Ignorable* or *Missing Completely at Random* if there is no relationship between the missingness of the data and any values, observed or missing.\n",
    "    - MCAR doesn't bias the observed data.\n",
    "\n",
    "* **MAR**:  Data is *conditionally ignorable* or *Missing at Random* if there is a systematic relationship between the propensity of missing values and the observed data, but not the missing data. \n",
    "    - MAR biases the observed data, but is fixable.\n",
    "\n",
    "* **NMAR**: Data is *non-ignorable* or *\"Not Missing at Random\"* if there is a relationship between the propensity of a value to be missing and its values.\n",
    "    - non-ignorable missing data biases the observed data in unobservable ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Unconditionally Ignorable (MCAR) definition:\n",
    "\n",
    "Suppose we have:\n",
    "- a dataset $Y$ with observed values $Y_{obs}$ and missing values $Y_{mis}$.\n",
    "- a parameter $\\psi$ independent of the dataset.\n",
    "\n",
    "**MCAR**: Data is *Unconditionally ignorable* if \n",
    "\n",
    "$$Pr({\\rm data\\ is\\ present\\ } | Y_{obs}, Y_{mis}, \\psi) = Pr({\\rm data\\ is\\ present\\ } |\\ \\psi)$$\n",
    "\n",
    "That is, adding information on the dataset doesn't change likelihood data is missing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditionally ignorable (MAR) definition\n",
    "\n",
    "Suppose we have:\n",
    "- a dataset $Y$ with observed values $Y_{obs}$ and missing values $Y_{mis}$.\n",
    "- a parameter $\\psi$ independent of the dataset.\n",
    "\n",
    "\n",
    "**MAR**: Data is *Conditionally ignorable* if \n",
    "\n",
    "$$Pr({\\rm data\\ is\\ present\\ } | Y_{obs}, Y_{mis}, \\psi) = Pr({\\rm data\\ is\\ present\\ } |\\ Y_{obs}, \\psi)$$\n",
    "\n",
    "That is, *MAR data is actually MCAR, conditional on $Y_{obs}$*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Non-ignorable missing data (NMAR ) definition\n",
    "\n",
    "Suppose we have:\n",
    "- a dataset $Y$ with observed values $Y_{obs}$ and missing values $Y_{mis}$.\n",
    "- a parameter $\\psi$ independent of the dataset.\n",
    "\n",
    "\n",
    "**NMAR**: Data is *non-ignorably missing* if \n",
    "\n",
    "$$Pr({\\rm data\\ is\\ present\\ }| Y_{obs}, Y_{mis}, \\psi)$$\n",
    "\n",
    "does not simplify. That is, in NMAR$ data, missingness is dependent on the missing value itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How to assess the mechanism of missingness: NMAR\n",
    "* Cannot determine NMAR from the data alone; it depends on the unobserved.\n",
    "* Must be reasoned by the data generating process, or more data should be collected.\n",
    "* How strong the dependence on $Y_{mis}$ influences the strength of NMAR\n",
    "    - If the dependence on the missing values is weak, then *most* the missingness is explainable by observed values!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How to assess the mechanism of missingness: MAR\n",
    "\n",
    "* Data are MAR if missingness only depends on *obsvered* data.\n",
    "* Data is MAR if it's determined to not be NMAR (assumption on data generating process).\n",
    "* Adding further measurements may reduce the effect of NMAR.\n",
    "    - income in census is NMAR; less so when adding geography, education, race..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How to assess the mechanism of missingness: MCAR\n",
    "\n",
    "Given the assumption of MAR, you can test if a data are MCAR.\n",
    "\n",
    "A column `c_test` is MCAR if its missingness $R$ is independent of the data.\n",
    "* For each column `c`, check that the missingness rates of `c_test` are the same across values of `c`.\n",
    "* That is, the distribution of `c` when `c_test.isull()` is 'the same' as the distribution of `c` when `c_test.notnull()`.\n",
    "* The phrase 'the same' needs to be made statistically precise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Checking data are MCAR: heights data\n",
    "* Start with complete dataset of child heights, sex of the child, and parent heights.\n",
    "* Blank out rows to create MCAR data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = pd.read_csv('data/galton.csv')\n",
    "\n",
    "heights['child'] = heights.childHeight\n",
    "heights = heights.drop(['family', 'midparentHeight', 'children', 'childNum', 'childHeight'], axis=1)\n",
    "heights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of heights\n",
    "pd.plotting.scatter_matrix(heights.drop('gender', axis=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create missing data\n",
    "# How was it created?\n",
    "np.random.seed(42)\n",
    "\n",
    "heights_mcar = heights.copy()\n",
    "idx = heights_mcar.sample(frac=0.3).index\n",
    "heights_mcar.loc[idx, 'child'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_mcar.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Verifying that child heights are MCAR in `heights_mcar`\n",
    "* Check the data look the 'same' when `height` is null vs not-null\n",
    "    - Is the empirical distribution of gender similar for null/not-null?\n",
    "    - Is the empirical distribution of heights similar for null/not-null?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_mcar.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distr = (\n",
    "    heights_mcar\n",
    "    .assign(is_null=heights_mcar.child.isnull())\n",
    "    .pivot_table(index='is_null', columns='gender', aggfunc='size')\n",
    "    .apply(lambda x:x / x.sum(), axis=1)\n",
    ")\n",
    "distr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing Null vs. Non-Null (`child`) distributions: `gender`\n",
    "\n",
    "* Are the distributions 'similar enough'? \n",
    "    - If yes, then missingness of `child` is *not* dependent on `gender`\n",
    "* Use a permutation test to assess the two distributions are similar.\n",
    "* For categorical columns, use TVD as the test-statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distr.T.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repetitions = 500\n",
    "\n",
    "tvds = []\n",
    "for _ in range(n_repetitions):\n",
    "    \n",
    "    # shuffle the gender column\n",
    "    shuffled_col = (\n",
    "        heights_mcar['gender']\n",
    "        .sample(replace=False, frac=1)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    \n",
    "    # put them in a table\n",
    "    shuffled = (\n",
    "        heights_mcar\n",
    "        .assign(**{\n",
    "            'gender': shuffled_col,\n",
    "            'is_null': heights_mcar['child'].isnull()\n",
    "        })\n",
    "    )\n",
    "    \n",
    "    # compute the tvd\n",
    "    shuffled = (\n",
    "        shuffled\n",
    "        .pivot_table(index='is_null', columns='gender', aggfunc='size')\n",
    "        .apply(lambda x:x / x.sum(), axis=1)\n",
    "    )\n",
    "    \n",
    "    tvd = shuffled.diff().iloc[-1].abs().sum() / 2\n",
    "    # add it to the list of results\n",
    "    \n",
    "    tvds.append(tvd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = distr.diff().iloc[-1].abs().sum() / 2\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval = np.mean(tvds > obs)\n",
    "pd.Series(tvds).plot(kind='hist', density=True, alpha=0.8, title='p-value: %f' % pval)\n",
    "plt.scatter(obs, 0, color='red', s=40);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing Null vs. Non-Null (`child` height) distributions: `father` (height)\n",
    "\n",
    "* Are the distributions 'similar enough'? \n",
    "    - If yes, then missingness of `child` is *not* dependent on height of `father`.\n",
    "    - If no, then e.g. taller fathers are more likely to not report child height.\n",
    "* In this case, it's 'clear' the distributions are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heights: counts\n",
    "(\n",
    "    heights_mcar\n",
    "    .assign(is_null=heights_mcar.child.isnull())\n",
    "    .groupby('is_null')\n",
    "    .father\n",
    "    .plot(kind='hist', legend=True, title='father height by missingness of child height')\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heights: distributions\n",
    "(\n",
    "    heights_mcar\n",
    "    .assign(is_null=heights_mcar.child.isnull())\n",
    "    .groupby('is_null')\n",
    "    .father\n",
    "    .plot(kind='kde', legend=True, title='father height by missingness of child height')\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Child heights data: MAR\n",
    "* MAR is an *assumption* from the data\n",
    "    - Is it reasonable to assume that a missing `child` height is explainable using the gender of the child and the height of the parents?\n",
    "* Once MAR is assumed, can show data is *not* MCAR\n",
    "    - Show how missingness of `child` depends on other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build MAR dataset\n",
    "\n",
    "heights_mar = heights.copy()\n",
    "for i, row in heights.iterrows():\n",
    "    rand = np.random.uniform()\n",
    "    if (row['father'] > 72) and rand < 0.5:\n",
    "        heights_mar.loc[i, 'child'] = np.NaN\n",
    "    elif (row['gender'] == 'female') and rand > 0.7:\n",
    "        heights_mar.loc[i, 'child'] = np.NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different missingness rates -- not MCAR\n",
    "\n",
    "distr = (\n",
    "    heights_mar\n",
    "    .assign(is_null=heights_mar.child.isnull())\n",
    "    .pivot_table(index='is_null', columns='gender', aggfunc='size')\n",
    "    .apply(lambda x:x / x.sum(), axis=1)\n",
    ")\n",
    "distr.T.plot(kind='bar', title='Distribution of Gender when child height is null/not-null');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different missingness rates -- not MCAR\n",
    "# Why is the right side of the graph different?\n",
    "\n",
    "(\n",
    "    heights_mar\n",
    "    .assign(is_null=heights_mar.child.isnull())\n",
    "    .groupby('is_null')\n",
    "    .father\n",
    "    .plot(kind='kde', legend=True, title='father height by missingness of child height')\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Missingness of `child` attribute: MAR case\n",
    "\n",
    "* The distributions above are clearly different.\n",
    "* What if their similarity was harder to determine? \n",
    "    - Permutation Test: are the distributions of column `X` when `child` is Null/Not-Null different?\n",
    "* For dependence on a categorical attribute: use TVD for the test-statistic.\n",
    "* For dependence on a quantitative attribute: ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## When are two quantitative distributions 'the same'?\n",
    "* Need a way to measure the 'distance' between distributions (i.e. a statistic)\n",
    "* Are the differences in these distributions due to noise? or significant?\n",
    "* Attempt #1:\n",
    "    - If two distributions have different means, then they're likely different distributions!\n",
    "    - Run a permutation test for differences in means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    heights_mar\n",
    "    .assign(is_null=heights_mar.child.isnull())\n",
    "    .groupby('is_null')\n",
    "    .father\n",
    "    .plot(kind='kde', legend=True, title='father height by missingness of child height')\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repetitions = 500\n",
    "\n",
    "means = []\n",
    "for _ in range(n_repetitions):\n",
    "    \n",
    "    # shuffle the gender column\n",
    "    shuffled_col = (\n",
    "        heights_mar['father']\n",
    "        .sample(replace=False, frac=1)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    \n",
    "    # put them in a table\n",
    "    shuffled = (\n",
    "        heights_mar\n",
    "        .assign(**{\n",
    "            'father': shuffled_col,\n",
    "            'is_null': heights_mar['child'].isnull()\n",
    "        })\n",
    "    )\n",
    "    \n",
    "    # compute the differences in means\n",
    "    mean = shuffled.groupby('is_null')['father'].mean().diff().abs().iloc[-1]\n",
    "    \n",
    "    means.append(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = heights_mar.assign(is_null=heights_mar['child'].isnull()).groupby('is_null')['father'].mean().diff().abs().iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval = np.mean(means > obs)\n",
    "pd.Series(means).plot(kind='hist', density=True, alpha=0.8, title='p-value: %f' % pval)\n",
    "plt.scatter(obs, 0, color='red', s=40);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discussion Question\n",
    "\n",
    "* We determined that two distributions were likely different because their means were different.\n",
    "* Can you think of two *different* distributions with the same mean?\n",
    "* What would our permutation test say about these distributions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Different distributions; same mean\n",
    "\n",
    "What does a permutation test using the test-statistic \"difference in means\" differentiate between distributions with similar means?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000 # number of samples for each distribution\n",
    "\n",
    "# Distribution 'A'\n",
    "a = pd.Series(np.random.normal(0, 1, size=N//2))\n",
    "b = pd.Series(np.random.normal(4, 1, size=N//2))\n",
    "distr1 = pd.concat([a,b], ignore_index=True)\n",
    "\n",
    "# Distribution 'B'\n",
    "distr2 = pd.Series(np.random.normal(distr1.mean(), distr1.std(), size=N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([distr1, distr2], axis=1, keys=['A', 'B']).unstack().reset_index().drop('level_1', axis=1)\n",
    "data = data.rename(columns={'level_0': 'group', 0: 'data'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mA, mB = data.groupby('group')['data'].mean().tolist()\n",
    "title = 'mean of A: %f\\n mean of B: %f' % (mA, mB)\n",
    "\n",
    "data.groupby('group')['data'].plot(kind='kde', legend=True, title=title);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repetitions = 500\n",
    "\n",
    "means = []\n",
    "for _ in range(n_repetitions):\n",
    "    \n",
    "    # shuffle the gender column\n",
    "    shuffled_col = (\n",
    "        data['data']\n",
    "        .sample(replace=False, frac=1)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    \n",
    "    # put them in a table\n",
    "    shuffled = (\n",
    "        data\n",
    "        .assign(**{\n",
    "            'data': shuffled_col,\n",
    "        })\n",
    "    )\n",
    "    \n",
    "    # compute the differences in means\n",
    "    mean = shuffled.groupby('group')['data'].mean().diff().abs().iloc[-1]\n",
    "    \n",
    "    means.append(mean)\n",
    "    \n",
    "    \n",
    "obs = data.groupby('group')['data'].mean().diff().abs().iloc[-1]\n",
    "\n",
    "pval = np.mean(means > obs)\n",
    "\n",
    "pd.Series(means).plot(kind='hist', density=True, alpha=0.8, title='p-value: %f' % pval)\n",
    "\n",
    "plt.scatter(obs, 0, color='red', s=40);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Telling quantitative distributions apart\n",
    "\n",
    "* Need a better test-statistic to differentiate between distributions!\n",
    "* Need a 'distance' between quantitative distributions:\n",
    "    - Measure the (absolute) difference between probabilities for nearby events?\n",
    "    - Why can't we use TVD?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('group')['data'].plot(kind='kde', legend=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## KS-Statistic\n",
    "    \n",
    "* Kolmogorov-Smirnov test-statistic: similarity between two distributions.\n",
    "* KS-statistics roughly measures the *area* between two empirical distributions.\n",
    "* Defined using the *Cumulative Distribution Function* instead of density function.\n",
    "* Python library: `scipy.stats.ks_2samp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpA = data.loc[data['group'] == 'A', 'data']\n",
    "gpB = data.loc[data['group'] == 'B', 'data']\n",
    "\n",
    "obs = ks_2samp(gpA, gpB).statistic\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repetitions = 500\n",
    "\n",
    "ks_list = []\n",
    "for _ in range(n_repetitions):\n",
    "    \n",
    "    # shuffle the gender column\n",
    "    shuffled_col = (\n",
    "        data['data']\n",
    "        .sample(replace=False, frac=1)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    \n",
    "    # put them in a table\n",
    "    shuffled = (\n",
    "        data\n",
    "        .assign(**{\n",
    "            'data': shuffled_col,\n",
    "        })\n",
    "    )\n",
    "    \n",
    "    # compute the KS\n",
    "    grps = shuffled.groupby('group')['data']\n",
    "    ks = ks_2samp(grps.get_group('A'), grps.get_group('B')).statistic\n",
    "    \n",
    "    ks_list.append(ks)\n",
    "    \n",
    "\n",
    "pval = np.mean(ks_list > obs)\n",
    "\n",
    "pd.Series(ks_list).plot(kind='hist', density=True, alpha=0.8, title='p-value: %f' % pval)\n",
    "\n",
    "plt.scatter(obs, 0, color='red', s=40);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The `ks_2samp` function\n",
    "\n",
    "* `scipy.stats.ks_2samp` actually returns *both* the statistic *and* a p-value.\n",
    "* The p-value is calculated using the permutation test we just performed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(gpA, gpB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary: Diagnosing Missingness Mechanisms\n",
    "\n",
    "### Case: NMAR\n",
    "\n",
    "* Can you make a reasonable case that the differences in missing vs not missing is largely explainable via *observed* data?\n",
    "    - If yes, then the missing data (column) 'missing at random' and the missing data is 'ignorable' (when handled properly).\n",
    "    - If no, then the missing data is 'not missing at random' (NMAR), or 'non-ignorable'. You must explicitly model missingness using assumptions on the data generating process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary: Diagnosing Missingness Mechanisms\n",
    "\n",
    "### Case: MAR\n",
    "\n",
    "* If missingness is explainable via *observed* data, then the missing data is 'missing at random' (MAR).\n",
    "* The distribution of missing data may still look different than the observed data!\n",
    "    - MAR requires you to understand how the missingness is dependent on other attributes in your data.\n",
    "* Use permutation tests to assess the dependence of misssing data on other attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary: Diagnosing Missingness Mechanisms\n",
    "\n",
    "### Case: MCAR\n",
    "\n",
    "* If missingness doesn't depend on any values in the observed data, it is 'unconditionally ignorable' (MCAR).\n",
    "* MCAR is equivalent to data being MAR, without dependence on any other columns.\n",
    "* If permutation tests point toward similar distributions of missing vs not-missing data, for *every* other column, then the data *may* be MCAR.\n",
    "    - Caution: you can't assert the data *are* MCAR, as permutation tests don't allow you to accept the null hypothesis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Assessing Missingness\n",
    "\n",
    "* Data on ticketed cars: VIN, Make, Year, Color\n",
    "* Is car color missing at random, dependent on car year?\n",
    "    * Are the distributions of year similar when color is null vs not null?\n",
    "    * How similar is similar enough?\n",
    "    \n",
    "Use a permutation test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv('cars.csv')\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proportion of car color missing\n",
    "cars.car_color.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars['car_color_isnull'] = cars.car_color.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    cars\n",
    "    .pivot_table(index='car_year', columns='car_color_isnull', values=None, aggfunc='size')\n",
    "    .fillna(0)\n",
    "    .apply(lambda x:x/x.sum())\n",
    "    .plot(title='distribution of car years by color=missing/not missing')\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: assessing missingness of car make on color\n",
    "\n",
    "* \"Are the two distributions (missing/not missing) of car make generated from the same distribution?\"\n",
    "* Car make is categorical. How to measure similarity without means?\n",
    "    - use total variation distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars['car_make_isnull'] = cars.car_make.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_distributions = (\n",
    "    cars\n",
    "    .pivot_table(columns='car_make_isnull', index='car_color', values=None, aggfunc='size')\n",
    "    .fillna(0)\n",
    "    .apply(lambda x:x/x.sum())\n",
    ")\n",
    "\n",
    "emp_distributions.plot(kind='bar', title='distribution of car colors');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_tvd = np.sum(np.abs(emp_distributions.diff(axis=1).iloc[:,-1])) / 2\n",
    "observed_tvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repetitions = 500\n",
    "\n",
    "car_make_color = cars.copy()[['car_color', 'car_make_isnull']]\n",
    "tvds = []\n",
    "for _ in range(n_repetitions):\n",
    "    \n",
    "    # shuffle the colors\n",
    "    shuffled_colors = (\n",
    "        car_make_color['car_color']\n",
    "        .sample(replace=False, frac=1)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    \n",
    "    # put them in a table\n",
    "    shuffled = (\n",
    "        car_make_color\n",
    "        .assign(**{'Shuffled Color': shuffled_colors})\n",
    "    )\n",
    "    \n",
    "    # compute the tvd\n",
    "    shuffed_emp_distributions = (\n",
    "        shuffled\n",
    "        .pivot_table(columns='car_make_isnull', index='Shuffled Color', values=None, aggfunc='size')\n",
    "        .fillna(0)\n",
    "        .apply(lambda x:x/x.sum())\n",
    "    )\n",
    "    \n",
    "    tvd = np.sum(np.abs(shuffed_emp_distributions.diff(axis=1).iloc[:,-1])) / 2\n",
    "    # add it to the list of results\n",
    "    \n",
    "    tvds.append(tvd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: visualize\n",
    "pd.Series(tvds).plot(kind='hist', density=True, alpha=0.8)\n",
    "plt.scatter(observed_tvd, 0, color='red', s=40);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: assessing missingness in payments data\n",
    "\n",
    "* Payment information for purchases: credit card type, credit card number, date of birth.\n",
    "* Is the credit card number missing at random dependent on the type of card?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments = pd.read_csv('payment.csv')\n",
    "payments['cc_isnull'] = payments.credit_card_number.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_distributions = (\n",
    "    payments\n",
    "    .pivot_table(columns='cc_isnull', index='credit_card_type', aggfunc='size')\n",
    "    .fillna(0)\n",
    "    .apply(lambda x:x / x.sum())\n",
    ")\n",
    "\n",
    "emp_distributions.plot(kind='bar', title='distribution of card types');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_tvd = np.sum(np.abs(emp_distributions.diff(axis=1).iloc[:,-1])) / 2\n",
    "observed_tvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repetitions = 500\n",
    "\n",
    "payments_type = payments.copy()[['credit_card_type', 'cc_isnull']]\n",
    "tvds = []\n",
    "for _ in range(n_repetitions):\n",
    "    \n",
    "    # shuffle the colors\n",
    "    shuffled_types = (\n",
    "        payments_type['credit_card_type']\n",
    "        .sample(replace=False, frac=1)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    \n",
    "    # put them in a table\n",
    "    shuffled = (\n",
    "        payments_type\n",
    "        .assign(**{'Shuffled Types': shuffled_types})\n",
    "    )\n",
    "    \n",
    "    # compute the tvd\n",
    "    shuffed_emp_distributions = (\n",
    "        shuffled\n",
    "        .pivot_table(columns='cc_isnull', index='Shuffled Types', values=None, aggfunc='size')\n",
    "        .fillna(0)\n",
    "        .apply(lambda x:x/x.sum())\n",
    "    )\n",
    "    \n",
    "    tvd = np.sum(np.abs(shuffed_emp_distributions.diff(axis=1).iloc[:,-1])) / 2\n",
    "    # add it to the list of results\n",
    "    \n",
    "    tvds.append(tvd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: assessing missingness in payments data\n",
    "\n",
    "* Is the credit card number missing at random dependent on the type of card?\n",
    "* As always, set significance level **beforehand**:\n",
    "    - How important is the column in the modeling process?\n",
    "    - How many null values are there?\n",
    "* Consideration: how important is a faithful imputation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: visualize\n",
    "pd.Series(tvds).plot(kind='hist', density=True, alpha=0.8)\n",
    "plt.scatter(observed_tvd, 0, color='red', s=40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p-value\n",
    "np.count_nonzero(tvds <= observed_tvd) / len(tvds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: assessing missingness in payments data\n",
    "\n",
    "* Is the credit card number missing at random dependent on the age of shopper?\n",
    "* For quantitative distributions, we've compared means of two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments['date_of_birth'] = pd.to_datetime(payments.date_of_birth)\n",
    "payments['age'] = (2019 - payments.date_of_birth.dt.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are the distributions similar?\n",
    "# Where are the differences? Are they noise, or real?\n",
    "payments.groupby('cc_isnull').age.plot(kind='kde', title='distribution of ages by missingness of CC', legend=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a permutation test\n",
    "observed_difference, differences = run_perm_test_mean(payments, 'cc_isnull', 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: visualize\n",
    "pd.Series(differences).plot(kind='hist', density=True, alpha=0.8)\n",
    "plt.scatter(observed_difference, 0, color='red', s=40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p-value\n",
    "np.count_nonzero(differences <= observed_difference) / len(differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: assessing missingness in payments data\n",
    "\n",
    "* Is the credit card number missing at random dependent on the age of shopper?\n",
    "* The two distributions \"look different\", but have similar means.\n",
    "    - Means may be too coarse a statistic\n",
    "    - Need a different metric for quantitative distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments.groupby('cc_isnull').age.plot(kind='kde', title='distribution of ages by missingness of CC', legend=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pdf_cdf(payments);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_ks, _ = ks_2samp(\n",
    "    payments.loc[payments['cc_isnull'], 'age'],\n",
    "    payments.loc[~payments['cc_isnull'], 'age']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repetitions = 500\n",
    "\n",
    "kslist = []\n",
    "for _ in range(n_repetitions):\n",
    "    \n",
    "    # shuffle the ages\n",
    "    shuffled_age = (\n",
    "        payments['age']\n",
    "        .sample(replace=False, frac=1)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    \n",
    "    # \n",
    "    shuffled = (\n",
    "        payments\n",
    "        .assign(**{'Shuffled Age': shuffled_age})\n",
    "    )\n",
    "\n",
    "    ks, _ = ks_2samp(\n",
    "        shuffled.loc[shuffled['cc_isnull'], 'Shuffled Age'],\n",
    "        shuffled.loc[~shuffled['cc_isnull'], 'Shuffled Age']\n",
    "    )\n",
    "    \n",
    "    # add it to the list of results\n",
    "    kslist.append(ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(kslist).plot(kind='hist', density=True, alpha=0.8)\n",
    "plt.scatter(observed_ks, 0, color='red', s=40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p-value\n",
    "np.count_nonzero(kslist >= observed_ks) / len(kslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random.normal(size=100)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "livereveal": {
   "scroll": true,
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
